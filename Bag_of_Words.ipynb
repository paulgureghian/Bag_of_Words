{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bag_of_Words.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paulgureghian/Bag_of_Words/blob/master/Bag_of_Words.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "SBZOFCxSL5aX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### **Created by Paul A. Gureghian in April of 2019.**"
      ]
    },
    {
      "metadata": {
        "id": "K9vSRoYWMGve",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### **This scientific notebook contains Python code to generate a 'Bag Of Words' algorithm.**\n",
        "\n",
        "### **Generated vectors can be input to  Machine Learning algorithms such as 'Natural Language Processing'  (NLP).**"
      ]
    },
    {
      "metadata": {
        "id": "y8c9tBbpNDKA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Import packages\n",
        "import re\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N_s7PSk8Lzri",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f34323a5-84ae-4de2-9ea9-91c4f18ceac5"
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "Tokenize each the sentences, example\n",
        "Input : \"John likes to watch movies. Mary likes movies too\"\n",
        "Ouput : \"John\",\"likes\",\"to\",\"watch\",\"movies\",\"Mary\",\"likes\",\"movies\",\"too\"\n",
        "\n",
        "'''"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nTokenize each the sentences, example\\nInput : \"John likes to watch movies. Mary likes movies too\"\\nOuput : \"John\",\"likes\",\"to\",\"watch\",\"movies\",\"Mary\",\"likes\",\"movies\",\"too\"\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "4V1VDR7mNwuj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Define 'tokenize' function\n",
        "### Tokenization is the act of breaking up a sequence of strings into pieces\n",
        "\n",
        "def tokenize(sentences):\n",
        "    words = []\n",
        "    for sentence in sentences:\n",
        "        w = word_extraction(sentence)\n",
        "        words.extend(w)\n",
        "        \n",
        "    words = sorted(list(set(words)))\n",
        "    return words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s5314yCwOuby",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Define 'word_extraction' function \n",
        "### Word_Extraction cleans the text by ignoring certain words  \n",
        "\n",
        "def word_extraction(sentence):\n",
        "    ignore = ['a', \"the\", \"is\"]\n",
        "    words = re.sub(\"[^\\w]\", \" \",  sentence).split()\n",
        "    cleaned_text = [w.lower() for w in words if w not in ignore]\n",
        "    return cleaned_text    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t_80l0GFQIUx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Define 'generate_bow' function\n",
        "### Build vocabulary and generate vectors\n",
        "\n",
        "def generate_bow(allsentences):    \n",
        "    vocab = tokenize(allsentences)\n",
        "    print(\"Word List for Document \\n{0} \\n\".format(vocab));\n",
        "\n",
        "    for sentence in allsentences:\n",
        "        words = word_extraction(sentence)\n",
        "        bag_vector = numpy.zeros(len(vocab))\n",
        "        for w in words:\n",
        "            for i,word in enumerate(vocab):\n",
        "                if word == w: \n",
        "                    bag_vector[i] += 1\n",
        "                    \n",
        "        print(\"{0} \\n{1}\\n\".format(sentence,numpy.array(bag_vector)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gkx_rtDLROJv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Input sentences \n",
        "\n",
        "allsentences = [\"Joe waited for the train\", \"The train was late\", \"Mary and Samantha took the bus\", \n",
        "            \"I looked for Mary and Samantha at the bus station\", \n",
        "            \"Mary and Samantha arrived at the bus station early but waited until noon for the bus\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jwaqH445RXI_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "97e5a6dd-caba-4903-83a3-7b2c5272ba01"
      },
      "cell_type": "code",
      "source": [
        "### Call to 'generate_bow' function with 'allsentences' as the argument\n",
        "generate_bow(allsentences)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word List for Document \n",
            "['and', 'arrived', 'at', 'bus', 'but', 'early', 'for', 'i', 'joe', 'late', 'looked', 'mary', 'noon', 'samantha', 'station', 'the', 'took', 'train', 'until', 'waited', 'was'] \n",
            "\n",
            "Joe waited for the train \n",
            "[0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.]\n",
            "\n",
            "The train was late \n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1.]\n",
            "\n",
            "Mary and Samantha took the bus \n",
            "[1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0.]\n",
            "\n",
            "I looked for Mary and Samantha at the bus station \n",
            "[1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
            "\n",
            "Mary and Samantha arrived at the bus station early but waited until noon for the bus \n",
            "[1. 1. 1. 2. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0.]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iEX-o4GYX6RF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### **As you can see, each sentence was compared with our word list generated in Step 1. Based on the comparison, the vector element value may be incremented. These vectors can be used in ML algorithms for document classification and predictions.**"
      ]
    }
  ]
}